# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c2faw2-209gYqTA_yb85m6Mx0d82mH9b
"""

#Importing the essential libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.ensemble import RandomForestClassifier
import pickle


sns.set(style='whitegrid')

#Loading the dataset
from google.colab import files
uploaded = files.upload()



import io
df = pd.read_csv(next(iter(uploaded.keys())))
df.shape

#Quicklook the dataset
df.head()
df.info()
df.isnull().sum()

# Cleaning & Preprocessing
#Convert TotalCharges if required
if 'TotalCharges' in df.columns:
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())

# Drop customerID if present
if 'customerID' in df.columns:
    df = df.drop('customerID', axis=1)

# Encode target
if 'Churn' in df.columns:
    df['Churn'] = df['Churn'].map({'Yes':1,'No':0})

# Identify object columns
cat_cols = df.select_dtypes(include=['object']).columns.tolist()
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()

print('Categorical columns:', cat_cols)
print('Numerical columns:', num_cols)

#One-hot encoding & final dataset
# One-hot encode categorical columns
df_encoded = pd.get_dummies(df, drop_first=True)


# Sanity check
print('Shape after encoding:', df_encoded.shape)

#Train-test split
X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']


X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.2, random_state=42, stratify=y)


print('Train set:', X_train.shape, 'Test set:', X_test.shape)

#Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Baseline Random Forest model
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1️⃣ Define the model
rf = RandomForestClassifier(n_estimators=200, random_state=42)

# 2️⃣ Train the model
rf.fit(X_train, y_train)

# 3️⃣ Make predictions
pred = rf.predict(X_test)

# 4️⃣ Evaluate
print('Accuracy:', accuracy_score(y_test, pred))
print(classification_report(y_test, pred))

# 5️⃣ Confusion matrix
cm = confusion_matrix(y_test, pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

#Feature importance
importances = pd.Series(rf.feature_importances_, index=X.columns)
importances = importances.sort_values(ascending=False)
importances.head(20)


# Plot top 10
plt.figure(figsize=(8,6))
importances.head(10).plot(kind='bar')
plt.title('Top 10 Feature Importances')
plt.show()

#ROC AUC
y_pred_prob = rf.predict_proba(X_test)[:,1]
auc = roc_auc_score(y_test, y_pred_prob)
print('ROC AUC:', auc)


fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()

#Hyperparameter tuning
param_grid = {
'n_estimators':[100,200],
'max_depth':[None,10,20],
'min_samples_split':[2,5]
}


gs = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, scoring='roc_auc')
gs.fit(X_train, y_train)
print('Best params:', gs.best_params_)
best = gs.best_estimator_


pred_best = best.predict(X_test)
print('Accuracy (best):', accuracy_score(y_test,pred_best))
print('ROC AUC (best):', roc_auc_score(y_test, best.predict_proba(X_test)[:,1]))